{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPuU8e/BAWmTjLpllSU7m17",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/skyqi/LangChain/blob/main/langchain_redis%E8%AE%B0%E5%BF%86%E5%AD%98%E5%82%A8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EWNerD8n16W_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sEn_d6Q-wdBI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b915d35c-faae-46c8-806d-0003269a5313"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "··········\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import getpass\n",
        "\n",
        "api_key = os.getenv(\"ZHIPUAI_API_KEY\")\n",
        "if api_key is None:\n",
        "  os.environ[\"ZHIPUAI_API_KEY\"] = getpass.getpass()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain langchain_community langchain_core\n",
        "!pip install langchain_openai\n",
        "!pip install ollama"
      ],
      "metadata": {
        "id": "iNT6tMxSxN0T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#智谱的模型\n",
        "from langchain_community.chat_models import ChatZhipuAI\n",
        "import os\n",
        "import getpass\n",
        "\n",
        "if os.getenv(\"ZHIPUAI_API_KEY\") is None:\n",
        "  os.environ[\"ZHIPUAI_API_KEY\"] = getpass.getpass()\n",
        "model_zhipu = ChatZhipuAI(\n",
        "    model=\"glm-4\",\n",
        "    temperature=0.5,\n",
        "    openai_api_base=\"https://open.bigmodel.cn/api/paas/v4/\"\n",
        ")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "VUepdp4hxNl0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MAQow_ZX42be"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "cSrTcSyw8Xrj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#亚马逊模型的调用\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.llms import Ollama\n",
        "from langchain_core.output_parsers import JsonOutputParser\n",
        "from langchain.chains import ConversationChain\n",
        "\n",
        "ollama_llm = Ollama(base_url='http://54.222.220.19:11435',model=\"llama3:8b\")\n",
        "\n",
        "# prompt_template = \"\"\"请提取与我相关的日程的时间和事件，\n",
        "# 您必须始终输出带有\"schedule_time”键和“schedule_event\"键的JSON对象。并且使用中文回复\n",
        "# {user_input}\"\"\"\n",
        "\n",
        "# llm_chain = LLMChain(\n",
        "#     llm = ollama_llm,\n",
        "#     prompt = ChatPromptTemplate.from_template(prompt_template)\n",
        "# )\n",
        "# user_json = llm_chain.invoke({\"user_input\":\"今天是2024-7-6，我明天去体育馆打球。小明后天去武汉办事\"})\n",
        "\n"
      ],
      "metadata": {
        "id": "kpLubnuX5Acq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1WBm0yEknpl7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "cZjlej9J2d8g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install redis -i https://pypi.doubanio.com/simple\n",
        "#!pip install langchain -i https://pypi.doubanio.com/simple\n",
        "!pip install -U langchain-community"
      ],
      "metadata": {
        "id": "4lyFSZWMDStc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import redis\n",
        "from langchain.schema import HumanMessage\n",
        "\n",
        "# Redis 服务器配置信息\n",
        "redis_host = '101.43.100'  # Redis 服务器的地址，如果是远程服务器，请替换为相应的 IP 地址\n",
        "redis_port = 8379        # Redis 服务器的端口，默认为 6379\n",
        "redis_password = ''     # 如果 Redis 服务器设置了密码，在这里设置\n",
        "\n",
        "\n",
        "\n",
        "# 创建 HumanMessage 实例\n",
        "human_message = HumanMessage(content=\"你好，这是一个人工智能助手。\")\n",
        "\n",
        "r = redis.Redis(host=redis_host,password=redis_password, port=redis_port, db=0)\n",
        "\n",
        "# 将 HumanMessage 对象序列化为字符串（例如 JSON）\n",
        "import json\n",
        "message_str = json.dumps(human_message.dict())\n",
        "\n",
        "# 将序列化后的消息存储到 Redis\n",
        "# 这里我们使用一个简单的键名 'human_message'，你可以根据需要修改它\n",
        "r.set('human_message', message_str)\n",
        "\n",
        "# 如果需要从 Redis 读取消息，可以这样做：\n",
        "# retrieved_message_str = r.get('human_message')\n",
        "# if retrieved_message_str is not None:\n",
        "#     # 将字符串反序列化为 HumanMessage 对象\n",
        "#     retrieved_message = HumanMessage.parse_raw(retrieved_message_str)\n",
        "#     print(retrieved_message.content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0tn5Z92MDf98",
        "outputId": "4ca2db21-62da-4272-a23f-e5a08a6cae70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.chat_history import InMemoryChatMessageHistory\n",
        "from langchain.schema import HumanMessage\n",
        "\n",
        "# 创建 HumanMessage 实例\n",
        "human_message = HumanMessage(content=\"你好，这是一个人工智能助手。\")\n",
        "chat_history = InMemoryChatMessageHistory()\n",
        "chat_history.add_message(human_message)\n",
        "print(chat_history.messages)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "70avKIgFPHjA",
        "outputId": "917d0257-dacf-4d23-889d-f94408c71fa9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[HumanMessage(content='你好，这是一个人工智能助手。')]\n"
          ]
        }
      ]
    }
  ]
}